{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your Deep Neural Network: Step by Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chào mừng bạn đến với bài tập tuần 4 (phần 1/2)! \n",
    "Trước đây bạn đã đào tạo Mạng nơ ron 2 lớp (với một lớp ẩn duy nhất). \n",
    "Tuần này, bạn sẽ xây dựng một mạng nơ-ron sâu, với bao nhiêu lớp tùy thích!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trong sổ tay này, bạn sẽ thực hiện tất cả các chức năng cần thiết để xây dựng một mạng nơ-ron sâu.\n",
    "* Trong bài tập tiếp theo, bạn sẽ sử dụng các chức năng này để xây dựng một mạng nơron sâu để phân loại hình ảnh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sau nhiệm vụ này, bạn sẽ có thể:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sử dụng các đơn vị phi tuyến tính như ReLU để cải thiện mô hình của bạn\n",
    "*Xây dựng mạng nơ-ron sâu hơn (với nhiều hơn 1 lớp ẩn)\n",
    "*Triển khai một lớp mạng thần kinh dễ sử dụng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Chỉ số trên $[l]$  biểu thị một số lượng được liên kết với  $l^{th}$ lớp\n",
    "  * Ví dụ :$a^{[L]}$ là các $L^{th}$m lớp kích hoạt $W^{[L]}$ và $b^{[L]}$ là các $L^{th}$ lớp tham số.\n",
    "* Chỉ số trên $(i)$ biểu thị một số lượng được liên kết với $i^{th}$ ví dụ.\n",
    "  * Ví dụ : $x^{(i)}$ là các $i^{th}$ ví dụ đâo tạo\n",
    "* Tập lệnh thấp hơn $i$ biểu thi các $i^{th}$ mục nhập của 1 vecto\n",
    "  * Ví dụ $a^{[l]}_i$ biểu thị các $i^{th}$ mục nhập của $l^{th}$ các lớp kích hoat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, hãy nhập tất cả các thư viện mà bạn sẽ cần trong quá trình chạy mạng nơ-ron này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* numpy là gói chính cho tính toán khoa học với Python.\n",
    "* matplotlib là một thư viện để vẽ đồ thị bằng Python.\n",
    "* rnn_utils cung cấp một số chức năng cần thiết cho sổ tay này.\n",
    "* các testCase cung cấp một số trường hợp thử nghiệm để đánh giá tính đúng đắn của các chức năng của bạn\n",
    "* np.random.seed (1) được sử dụng để giữ cho tất cả các lệnh gọi hàm ngẫu nhiên nhất quán. Nó sẽ giúp chúng tôi đánh giá công việc của bạn. Vui lòng không thay đổi chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from testCases_v4a import *\n",
    "from dnn_utils_v2 import sigmoid, sigmoid_backward, relu, relu_backward\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Outline of the Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để xây dựng mạng nơ-ron của mình, bạn sẽ thực hiện một số \"chức năng trợ giúp\".\n",
    "Các hàm trợ giúp này sẽ được sử dụng trong nhiệm vụ tiếp theo để xây dựng mạng nơ ron hai lớp và mạng nơ ron lớp L.\n",
    "Mỗi chức năng trợ giúp nhỏ mà bạn thực hiện sẽ có hướng dẫn chi tiết hướng dẫn bạn qua các bước cần thiết.\n",
    "Đây là bản phác thảo của bài tập này, bạn sẽ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Khởi tạo các tham số cho mạng hai lớp và L- cho mạng nơ ron lớp  .\n",
    "* Triển khai mô-đun lan truyền thuận (được hiển thị bằng màu tím trong hình bên dưới).\n",
    "    * Hoàn thành phần LINEAR của bước truyền tiến của một lớp (dẫn đến Z[l]).\n",
    "    * Chúng tôi cung cấp cho bạn chức năng ACTIVATION (relu / sigmoid).\n",
    "    * Kết hợp hai bước trước đó thành một chức năng chuyển tiếp [LINEAR-> ACTIVATION] mới.\n",
    "    * Xếp chồng hàm chuyển tiếp [LINEAR-> RELU] L-1 lần (cho lớp 1 đến lớp L-1) và thêm [LINEAR-> SIGMOID] vào cuối (cho lớp cuối cùng LL). Điều này cung cấp cho bạn một hàm L_model_osystem mới.\n",
    "* Tính toán loss.\n",
    "* Thực hiện mô-đun lan truyền ngược (được biểu thị bằng màu đỏ trong hình bên dưới).\n",
    "    * Hoàn thành phần LINEAR của bước lan truyền ngược của lớp.\n",
    "    * Chúng tôi cung cấp cho bạn gradient của hàm ACTIVATE (relu_backward / sigmoid_backward)\n",
    "    * Kết hợp hai bước trước đó thành một chức năng quay lại [LINEAR-> ACTIVATION] mới.\n",
    "    * Chồng [LINEAR-> RELU] lùi L-1 lần và thêm [LINEAR-> SIGMOID] lùi vào hàm L_model_backward mới\n",
    "* Cuối cùng là cập nhật các thông số."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/final outline.png\" style=\"width:800px;height:500px;\">\n",
    "<caption><center> **Figure 1**</center></caption><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lưu ý**: Rằng đối với mỗi hàm tiến, có một hàm lùi tương ứng. Đó là lý do tại sao ở mỗi bước của mô-đun chuyển tiếp của bạn, bạn sẽ lưu trữ một số giá trị trong bộ nhớ cache. Các giá trị được lưu trong bộ nhớ cache rất hữu ích cho việc tính toán độ dốc Trong mô-đun backpropagation, sau đó bạn sẽ sử dụng bộ nhớ cache để tính toán các gradient. Bài tập này sẽ chỉ cho bạn chính xác cách thực hiện từng bước này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn sẽ viết hai hàm trợ giúp sẽ khởi tạo các tham số cho mô hình của bạn.\n",
    "Hàm đầu tiên sẽ được sử dụng để khởi tạo các tham số cho mô hình hai lớp.\n",
    "Cái thứ hai sẽ khái quát quá trình khởi tạo này thành các lớp L."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - 2-layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tập thể dục:** Tạo và khởi tạo các tham số của mạng nơ ron 2 lớp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cấu trúc của mô hình là: LINEAR -> RELU -> LINEAR -> SIGMOID.\n",
    "* Sử dụng khởi tạo ngẫu nhiên cho các ma trận tham số. Sử dụng np.random.randn (shape) * 0.01 với hình dạng chính xác.\n",
    "* Sử dụng khởi tạo bằng không cho các bias. Sử dụng np.zeros (shape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1 = np.random.randn(n_h,n_x)*0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.01624345 -0.00611756 -0.00528172]\n",
      " [-0.01072969  0.00865408 -0.02301539]]\n",
      "b1 = [[0.]\n",
      " [0.]]\n",
      "W2 = [[ 0.01744812 -0.00761207]]\n",
      "b2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(3,2,1)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**:\n",
    "       \n",
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <td> **W1** </td>\n",
    "    <td> [[ 0.01624345 -0.00611756 -0.00528172]\n",
    " [-0.01072969  0.00865408 -0.02301539]] </td> \n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td> **b1**</td>\n",
    "    <td>[[ 0.]\n",
    " [ 0.]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>**W2**</td>\n",
    "    <td> [[ 0.01744812 -0.00761207]]</td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td> **b2** </td>\n",
    "    <td> [[ 0.]] </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - L-layer Neural Network"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Việc khởi tạo cho một mạng nơron lớp L sâu hơn phức tạp hơn vì có nhiều ma trận tham số và vectơ bias hơn.\n",
    "Khi hoàn tất khởi tạo_parameters_deep, bạn nên đảm bảo rằng các kích thước của bạn khớp giữa mỗi lớp. \n",
    "Nhớ lại rằng  $n^{[l]}$  là số đơn vị trong lớp $l$. Vì vậy, ví dụ: nếu kích thước của đầu vào $X$ của chúng tôi là $(12288, 209)$ (với $m=209$ ví dụ) thì:\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Hãy nhớ rằng khi chúng ta tính toán $W X + b$ trong python, nó thực hiện phát sóng. Ví dụ, nếu: \n",
    "\n",
    "$$ W = \\begin{bmatrix}\n",
    "    j  & k  & l\\\\\n",
    "    m  & n & o \\\\\n",
    "    p  & q & r \n",
    "\\end{bmatrix}\\;\\;\\; X = \\begin{bmatrix}\n",
    "    a  & b  & c\\\\\n",
    "    d  & e & f \\\\\n",
    "    g  & h & i \n",
    "\\end{bmatrix} \\;\\;\\; b =\\begin{bmatrix}\n",
    "    s  \\\\\n",
    "    t  \\\\\n",
    "    u\n",
    "\\end{bmatrix}\\tag{2}$$\n",
    "\n",
    "Thì $WX + b$ sẽ như này:\n",
    "\n",
    "$$ WX + b = \\begin{bmatrix}\n",
    "    (ja + kd + lg) + s  & (jb + ke + lh) + s  & (jc + kf + li)+ s\\\\\n",
    "    (ma + nd + og) + t & (mb + ne + oh) + t & (mc + nf + oi) + t\\\\\n",
    "    (pa + qd + rg) + u & (pb + qe + rh) + u & (pc + qf + ri)+ u\n",
    "\\end{bmatrix}\\tag{3}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài tập**: Thực hiện khởi tạo cho Mạng thần kinh lớp L."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hướng dẫn**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cấu trúc của mô hình là *[LINEAR -> RELU] $ \\times$ (L-1) -> LINEAR -> SIGMOID* .Tức là nó có lớp $ L-1 $ sử dụng chức năng kích hoạt ReLU theo sau là lớp đầu ra có chức năng kích hoạt sigmoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sử dụng khởi tạo ngẫu nhiên cho các ma trận tham số w. Sử dụng `np.random.randn (shape) * 0.01`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sử dụng khởi tạo các số không cho các bias. Sử dụng `np.zeros (shape)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Chúng tôi sẽ lưu trữ $ n ^ {[l]} $, số lượng đơn vị trong các lớp khác nhau, trong một biến `layer_dims`.Ví dụ: `layer_dims` cho\" Mô hình phân loại dữ liệu phẳng \"từ tuần trước sẽ là [2,4,1]: \n",
    "        Có hai đầu vào, một lớp ẩn với 4 đơn vị ẩn và một lớp đầu ra có 1 đơn vị đầu ra .\n",
    "        Điều này có nghĩa là hình dạng của `W1` là (4,2),` b1` là (4,1), `W2` là (1,4) và` b2` là (1,1).\n",
    "        Bây giờ bạn sẽ tổng quát điều này thành các L lớp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Đây là cách triển khai cho $ L = 1 $ (mạng nơ-ron một lớp). Nó sẽ truyền cảm hứng cho bạn để triển khai trường hợp chung (mạng nơ-ron lớp L)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    if L == 1:\n",
    "        parameters[\"W\" + str(L)] = np.random.randn(layer_dims[1], layer_dims[0]) * 0.01\n",
    "        parameters[\"b\" + str(L)] = np.zeros((layer_dims[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters_deep\n",
    "\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "    for l in range(1, L):\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        parameters['W'+str(l)] =np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "W1 = [[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]\n",
      " [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]\n",
      " [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]\n",
      " [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[-0.01185047 -0.0020565   0.01486148  0.00236716]\n",
      " [-0.01023785 -0.00712993  0.00625245 -0.00160513]\n",
      " [-0.00768836 -0.00230031  0.00745056  0.01976111]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters_deep([5,4,3])\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**:\n",
    "       \n",
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <td>W1</td>\n",
    "    <td>[[ 0.01788628  0.0043651   0.00096497 -0.01863493 -0.00277388]\n",
    " [-0.00354759 -0.00082741 -0.00627001 -0.00043818 -0.00477218]\n",
    " [-0.01313865  0.00884622  0.00881318  0.01709573  0.00050034]\n",
    " [-0.00404677 -0.0054536  -0.01546477  0.00982367 -0.01101068]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>b1 </td>\n",
    "    <td>[[ 0.]\n",
    " [ 0.]\n",
    " [ 0.]\n",
    " [ 0.]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>W2 </td>\n",
    "    <td>[[-0.01185047 -0.0020565   0.01486148  0.00236716]\n",
    " [-0.01023785 -0.00712993  0.00625245 -0.00160513]\n",
    " [-0.00768836 -0.00230031  0.00745056  0.01976111]]</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>b2</td>\n",
    "    <td>[[ 0.]\n",
    " [ 0.]\n",
    " [ 0.]]</td> \n",
    "  </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Forward propagation module\n",
    "\n",
    "### 4.1 - Linear Forward \n",
    "Bây giờ bạn đã khởi tạo các tham số của mình, bạn sẽ thực hiện mô-đun lan truyền thuận. Bạn sẽ bắt đầu bằng cách thực hiện một số chức năng cơ bản mà bạn sẽ sử dụng sau này khi thực hiện mô hình. Bạn sẽ hoàn thành ba chức năng theo thứ tự sau:\n",
    "\n",
    "- LINEAR\n",
    "- LINEAR -> ACTIVATION ở vị trí ACTIVATION sẽ là một trong hai  ReLU hoặc Sigmoid. \n",
    "- [LINEAR -> RELU] $\\times$ (L-1) -> LINEAR -> SIGMOID (whole model)\n",
    "\n",
    "Mô-đun Linear Forward  (được vectơ hóa trên tất cả các ví dụ) tính toán các phương trình sau: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Z^{[l]} = W^{[l]}A^{[l-1]} +b^{[l]}\\tag{4}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi $A^{[0]} = X$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài tập**: Xây dựng phần Linear Forward của quá trình lan truyền thuận."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhắc nhở**:\n",
    "Biểu diễn toán học của đơn vị này là $ Z ^ {[l]} = W ^ {[l]} A ^ {[l-1]} + b ^ {[l]} $. Bạn cũng có thể thấy `np.dot ()` hữu ích. Nếu kích thước của bạn không khớp, việc dùng `W.shape` có thể hữu ích."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_forward\n",
    "\n",
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    Z = np.dot(W,A)+b\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = [[ 3.26295337 -1.23429987]]\n"
     ]
    }
   ],
   "source": [
    "A, W, b = linear_forward_test_case()\n",
    "\n",
    "Z, linear_cache = linear_forward(A, W, b)\n",
    "print(\"Z = \" + str(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kết quả mong đợi**:\n",
    "\n",
    "<table style = \"width: 35%\">\n",
    "  \n",
    "   <tr>\n",
    "     <td> Z  </td>\n",
    "     <td> [[3.26295337 -1.23429987]] </td>\n",
    "   </tr>\n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Linear-Activation Forward\n",
    "\n",
    "Trong sổ tay này, bạn sẽ sử dụng hai chức năng kích hoạt:\n",
    "\n",
    "- **Sigmoid**: $\\sigma(Z) = \\sigma(W A + b) = \\frac{1}{ 1 + e^{-(W A + b)}}$. Chúng tôi đã cung cấp cho bạn hàm `sigmoid`. Hàm này trả về **hai** item: giá trị kích hoạt \"` a` \"và\" `cache`\" có chứa \"` Z` \"(đó là những gì chúng ta sẽ đưa vào hàm backward tương ứng). Để sử dụng nó, bạn chỉ cần gọi:\n",
    "``` python\n",
    "A, activation_cache = sigmoid(Z)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ReLU**: Công thức toán học cho ReLu là $A = RELU(Z) = max(0, Z)$. Chúng tôi đã cung cấp cho bạn chức năng `relu`. Hàm này trả về **hai** item: giá trị kích hoạt \"` A` \"và\" `cache`\" có chứa \"` Z` \"(đó là những gì chúng ta sẽ đưa vào hàm backward  tương ứng). Để sử dụng nó, bạn chỉ cần gọi:\n",
    "``` python\n",
    "A, activation_cache = relu(Z)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để thuận tiện hơn, bạn sẽ nhóm hai chức năng (Linear và Activation) thành một chức năng (LINEAR->ACTIVATION).\n",
    "Do đó, bạn sẽ triển khai một hàm thực hiện bước tiến LINEAR, theo sau là bước chuyển tiếp ACTIVATION ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài tập**: Thực hiện lan truyền thuận của lớp *LINEAR-> ACTIVATION*. Công thức toán học là: $ A ^ {[l]} = g (Z ^ {[l]}) = g (W ^ {[l]} A ^ {[l-1]} + b ^ {[l]} ) $ trong đó kích hoạt \"g\" có thể là sigmoid () hoặc relu (). Sử dụng  linear_forward() và hàm hai chức năng kích hoạt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_activation_forward\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A,activation_cache = sigmoid(Z)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A,activation_cache = relu(Z)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With sigmoid: A = [[0.96890023 0.11013289]]\n",
      "With ReLU: A = [[3.43896131 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A_prev, W, b = linear_activation_forward_test_case()\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"sigmoid\")\n",
    "print(\"With sigmoid: A = \" + str(A))\n",
    "\n",
    "A, linear_activation_cache = linear_activation_forward(A_prev, W, b, activation = \"relu\")\n",
    "print(\"With ReLU: A = \" + str(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kết quả mong đợi**:\n",
    "       \n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td> With sigmoid: A </td>\n",
    "    <td > [[ 0.96890023  0.11013289]]</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> With ReLU: A  </td>\n",
    "    <td > [[ 3.43896131  0.        ]]</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lưu ý**: Trong học sâu, phép tính \"[LINEAR-> ACTIVATION]\" được tính là một lớp trong mạng nơ-ron chứ không phải hai lớp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) L-Layer Model \n",
    "\n",
    "Để thuận tiện hơn nữa khi triển khai $L$- lớp Neural Net, bạn sẽ cần một chức năng sao chép chức năng trước đó (`linear_activation_forward` với RELU) $L-1$ times, rồi tiếp theo sau đó với một `linear_activation_forward` với SIGMOID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/model_architecture_kiank.png\" style=\"width:600px;height:300px;\">\n",
    "<caption><center> **Figure 2** : *[LINEAR -> RELU] $\\times$ (L-1) -> LINEAR -> SIGMOID* model</center></caption><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài tập**: Thực hiện lan truyền thuận của mô hình trên.\n",
    "\n",
    "**Chỉ dẫn**: Trong đoạn mã dưới đây, biến `AL` sẽ biểu thị $A^{[L]} = \\sigma(Z^{[L]}) = \\sigma(W^{[L]} A^{[L-1]} + b^{[L]})$. (Điều này đôi khi còn được gọi là `Yhat`, tương tự, Đây là  $\\hat{Y}$.) \n",
    "\n",
    "**Gợi ý**:\n",
    "- Sử dụng các chức năng bạn đã viết trước đó\n",
    "- Sử dụng vòng lặp for để tái tạo [LINEAR->RELU] (L-1) thời gian\n",
    "- Đừng quên theo dõi các caches trong danh sách \"caches. Để thêm giá trị mới `c` vào`list`, bạn có thể sử dụng `list.append (c)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: L_model_forward\n",
    "\n",
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    \n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    for l in range(1,L):\n",
    "        A_prev = A\n",
    "        A,cache = linear_activation_forward(A_prev,parameters['W'+str(l)], parameters['b'+str(l)],'relu')\n",
    "        caches.append(cache)\n",
    "    ### END CODE HERE ###\n",
    "    AL,cache = linear_activation_forward(A,parameters['W'+str(L)], parameters['b'+str(L)],\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL = [[0.03921668 0.70498921 0.19734387 0.04728177]]\n",
      "Length of caches list = 3\n"
     ]
    }
   ],
   "source": [
    "X, parameters = L_model_forward_test_case_2hidden()\n",
    "AL, caches = L_model_forward(X, parameters)\n",
    "print(\"AL = \" + str(AL))\n",
    "print(\"Length of caches list = \" + str(len(caches)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <td>AL</td>\n",
    "    <td > [[ 0.03921668  0.70498921  0.19734387  0.04728177]]</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Length of caches list </td>\n",
    "    <td > 3 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuyệt quá! Bây giờ bạn có lan truyền thuận đầy đủ lấy đầu vào X và xuất ra một vectơ hàng $ A ^ {[L]} $ chứa các dự đoán của bạn. \n",
    "Nó cũng ghi lại tất cả các giá trị trung gian trong \"caches\". Sử dụng $ A ^ {[L]} $, bạn có thể tính toán chi phí dự đoán của mình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Cost function\n",
    "\n",
    "Bây giờ bạn sẽ thực hiện truyền tiến và truyền lùi. Bạn cần tính toán chi phí, bởi vì bạn muốn kiểm tra xem mô hình của bạn có thực sự đang học hay không.\n",
    "\n",
    "**Tập thể dục**: Tính toán cross-entropy chi phí $J$, sử dụng công thức sau: $$-\\frac{1}{m} \\sum\\limits_{i = 1}^{m} (y^{(i)}\\log\\left(a^{[L] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[L](i)}\\right)) \\tag{7}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y.\n",
    "    ### START CODE HERE ### (≈ 1 lines of code)\n",
    "    cost = (-1/m)*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.2797765635793422\n"
     ]
    }
   ],
   "source": [
    "Y, AL = compute_cost_test_case()\n",
    "\n",
    "print(\"cost = \" + str(compute_cost(AL, Y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kết quả mong đợi**:\n",
    "<table>\n",
    "    <tr>\n",
    "    <td> cost </td>\n",
    "    <td> 0.2797765635793422</td> \n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Backward propagation module\n",
    "\n",
    "Cũng giống như với lan truyền thuận, bạn sẽ triển khai các hàm trợ giúp cho việc lan truyền ngược. Hãy nhớ rằng truyền ngược được sử dụng để tính toán gradient của hàm mất mát liên quan đến các tham số."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nhắc nhở**: \n",
    "<img src=\"images/backprop_kiank.png\" style=\"width:650px;height:250px;\">\n",
    "<caption><center> \n",
    "**Figure 3** : Chuyển tiếp và lan truyền ngược cho *LINEAR->RELU->LINEAR->SIGMOID* <br> *Chúng ta các khối màu tím đại diện cho sự lan truyền thuận và các khối màu đỏ đại diện cho sự lan truyền ngược lại.*  </center></caption>\n",
    "\n",
    "<!-- \n",
    "Đối với những bạn là chuyên gia về giải tích (bạn không cần phải làm bài tập này), quy tắc chuỗi của phép tính có thể được sử dụng để tính đạo hàm của sự mất mát $\\mathcal{L}$ đối với $z^{[1]}$ trong mạng 2 lớp như sau:\n",
    "\n",
    "$$\\frac{d \\mathcal{L}(a^{[2]},y)}{{dz^{[1]}}} = \\frac{d\\mathcal{L}(a^{[2]},y)}{{da^{[2]}}}\\frac{{da^{[2]}}}{{dz^{[2]}}}\\frac{{dz^{[2]}}}{{da^{[1]}}}\\frac{{da^{[1]}}}{{dz^{[1]}}} \\tag{8} $$\n",
    "\n",
    "Để tính toán gradient $dW^{[1]} = \\frac{\\partial L}{\\partial W^{[1]}}$, bạn sử dụng quy tắc chuỗi trước đó và bạn làm $dW^{[1]} = dz^{[1]} \\times \\frac{\\partial z^{[1]} }{\\partial W^{[1]}}$. Trong quá trình backpropagation, ở mỗi bước, bạn nhân gradient hiện tại của mình với gradient tương ứng với lớp cụ thể để có được gradient bạn muốn.\n",
    "\n",
    "Tương tự, để tính toán gradient $db^{[1]} = \\frac{\\partial L}{\\partial b^{[1]}}$, bạn sử dụng quy tắc chuỗi và $db^{[1]} = dz^{[1]} \\times \\frac{\\partial z^{[1]} }{\\partial b^{[1]}}$.\n",
    "\n",
    "Đây là lý do tại sao chúng ta nói về ** backpropagation **.\n",
    "!-->\n",
    "\n",
    "Bây giờ, tương tự như truyền tiến, bạn sẽ xây dựng truyền ngược theo ba bước:\n",
    "- LINEAR backward\n",
    "- LINEAR -> ACTIVATION backward ở vị trí ACTIVATION tính toán dẫn xuất kích hoạt ReLU hoặc sigmoid\n",
    "- [LINEAR -> RELU] $\\times$ (L-1) -> LINEAR -> SIGMOID backward (whole model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 - Linear backward\n",
    "\n",
    "Cho lớp $l$, phần tuyến tính là: $Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$ (tiếp theo là một kích hoạt).\n",
    "\n",
    "Giả sử bạn đã tính toán đạo hàm $dZ^{[l]} = \\frac{\\partial \\mathcal{L} }{\\partial Z^{[l]}}$. Bạn muốn có được $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$.\n",
    "\n",
    "<img src=\"images/linearback_kiank.png\" style=\"width:250px;height:300px;\">\n",
    "<caption><center> **Figure 4** </center></caption>\n",
    "\n",
    "3 Đầu ra $(dW^{[l]}, db^{[l]}, dA^{[l-1]})$ được tính toán bằng cách sử dụng đầu vào $dZ^{[l]}$.Đây là công thức bạn cần:\n",
    "$$ dW^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial W^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l-1] T} \\tag{8}$$\n",
    "$$ db^{[l]} = \\frac{\\partial \\mathcal{J} }{\\partial b^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)}\\tag{9}$$\n",
    "$$ dA^{[l-1]} = \\frac{\\partial \\mathcal{L} }{\\partial A^{[l-1]}} = W^{[l] T} dZ^{[l]} \\tag{10}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài tập**: Sử dụng 3 công thức trên để triển khai linear_backward ()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_backward\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    ## START CODE HERE ### (≈ 3 lines of code)\n",
    "    dW = (1/m )* np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis = 1, keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_prev = [[-1.15171336  0.06718465 -0.3204696   2.09812712]\n",
      " [ 0.60345879 -3.72508701  5.81700741 -3.84326836]\n",
      " [-0.4319552  -1.30987417  1.72354705  0.05070578]\n",
      " [-0.38981415  0.60811244 -1.25938424  1.47191593]\n",
      " [-2.52214926  2.67882552 -0.67947465  1.48119548]]\n",
      "dW = [[ 0.07313866 -0.0976715  -0.87585828  0.73763362  0.00785716]\n",
      " [ 0.85508818  0.37530413 -0.59912655  0.71278189 -0.58931808]\n",
      " [ 0.97913304 -0.24376494 -0.08839671  0.55151192 -0.10290907]]\n",
      "db = [[-0.14713786]\n",
      " [-0.11313155]\n",
      " [-0.13209101]]\n"
     ]
    }
   ],
   "source": [
    "# Set up some test inputs\n",
    "dZ, linear_cache = linear_backward_test_case()\n",
    "\n",
    "dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kết quả mong đợi**:\n",
    "    \n",
    "```\n",
    "dA_prev = \n",
    " [[-1.15171336  0.06718465 -0.3204696   2.09812712]\n",
    " [ 0.60345879 -3.72508701  5.81700741 -3.84326836]\n",
    " [-0.4319552  -1.30987417  1.72354705  0.05070578]\n",
    " [-0.38981415  0.60811244 -1.25938424  1.47191593]\n",
    " [-2.52214926  2.67882552 -0.67947465  1.48119548]]\n",
    "dW = \n",
    " [[ 0.07313866 -0.0976715  -0.87585828  0.73763362  0.00785716]\n",
    " [ 0.85508818  0.37530413 -0.59912655  0.71278189 -0.58931808]\n",
    " [ 0.97913304 -0.24376494 -0.08839671  0.55151192 -0.10290907]]\n",
    "db = \n",
    " [[-0.14713786]\n",
    " [-0.11313155]\n",
    " [-0.13209101]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Linear-Activation backward\n",
    "\n",
    "Tiếp theo, bạn sẽ tạo một hàm kết hợp hai hàm trợ giúp: **`linear_backward`** và backward để kích hoạt **`linear_activation_backward`**. \n",
    "\n",
    "Để giúp bạn thực hiện `linear_activation_backward`, chúng tôi đã cung cấp hai hàm backward :\n",
    "- **`sigmoid_backward`**: Thực hiện truyền ngược cho đơn vị SIGMOID. Bạn có thể gọi nó như sau:\n",
    "\n",
    "```python\n",
    "dZ = sigmoid_backward(dA, activation_cache)\n",
    "```\n",
    "\n",
    "- **`relu_backward`**: Thực hiện truyền ngược cho đơn vị RELU. Bạn có thể gọi nó như sau:\n",
    "\n",
    "```python\n",
    "dZ = relu_backward(dA, activation_cache)\n",
    "```\n",
    "\n",
    "Nếu $g(.)$ nó là hàm kích hoạt, \n",
    "`sigmoid_backward` và `relu_backward` tính toán $$dZ^{[l]} = dA^{[l]} * g'(Z^{[l]}) \\tag{11}$$.  \n",
    "\n",
    "**Bài tập**: Triển khai backpropagation cho *LINEAR->lớp ACTIVATION* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_activation_backward\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ =relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db =linear_backward(dZ, linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid:\n",
      "dA_prev = [[ 0.11017994  0.01105339]\n",
      " [ 0.09466817  0.00949723]\n",
      " [-0.05743092 -0.00576154]]\n",
      "dW = [[ 0.10266786  0.09778551 -0.01968084]]\n",
      "db = [[-0.05729622]]\n",
      "\n",
      "relu:\n",
      "dA_prev = [[ 0.44090989 -0.        ]\n",
      " [ 0.37883606 -0.        ]\n",
      " [-0.2298228   0.        ]]\n",
      "dW = [[ 0.44513824  0.37371418 -0.10478989]]\n",
      "db = [[-0.20837892]]\n"
     ]
    }
   ],
   "source": [
    "dAL, linear_activation_cache = linear_activation_backward_test_case()\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(dAL, linear_activation_cache, activation = \"sigmoid\")\n",
    "print (\"sigmoid:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db) + \"\\n\")\n",
    "\n",
    "dA_prev, dW, db = linear_activation_backward(dAL, linear_activation_cache, activation = \"relu\")\n",
    "print (\"relu:\")\n",
    "print (\"dA_prev = \"+ str(dA_prev))\n",
    "print (\"dW = \" + str(dW))\n",
    "print (\"db = \" + str(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output with sigmoid:**\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td > dA_prev </td> \n",
    "    <td >[[ 0.11017994  0.01105339]\n",
    " [ 0.09466817  0.00949723]\n",
    " [-0.05743092 -0.00576154]] </td> \n",
    "  </tr> \n",
    "    <tr>\n",
    "    <td > dW </td> \n",
    "           <td > [[ 0.10266786  0.09778551 -0.01968084]] </td> \n",
    "  </tr>  \n",
    "    <tr>\n",
    "    <td > db </td> \n",
    "        <td > [[-0.05729622]] </td> \n",
    "  </tr> \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output with relu:**\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td > dA_prev </td> \n",
    "           <td > [[ 0.44090989  0.        ]\n",
    " [ 0.37883606  0.        ]\n",
    " [-0.2298228   0.        ]] </td> \n",
    "  </tr> \n",
    "    <tr>\n",
    "    <td > dW </td> \n",
    "           <td > [[ 0.44513824  0.37371418 -0.10478989]] </td> \n",
    "  </tr> \n",
    "    <tr>\n",
    "    <td > db </td> \n",
    "           <td > [[-0.20837892]] </td> \n",
    "  </tr> \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 - L-Model Backward\n",
    "\n",
    "Bây giờ bạn sẽ thực hiện lan truyenf ngược cho vô số lớp. Nhớ lại rằng khi bạn triển khai hàm `L_model_osystem`, ở mỗi lần lặp lại, bạn đã lưu trữ một bộ đệm ẩn chứa (X, W, b và z). Trong mô-đun lan truyền ngược, bạn sẽ sử dụng các biến đó để tính toán độ dốc. Do đó, trong hàm `L_model_backward`, bạn sẽ lặp lại tất cả các lớp ẩn trở lại, bắt đầu từ lớp $ L $. Trên mỗi bước, bạn sẽ sử dụng các giá trị được lưu trong bộ nhớ cache cho lớp $ l $ để sao chép thông qua lớp $ l $. Hình 5 dưới đây cho thấy đường chuyền lùi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mn_backward.png\" style=\"width:450px;height:300px;\">\n",
    "<caption><center>  **Figure 5** : Backward pass  </center></caption>\n",
    "\n",
    "** Khởi tạo backpropagation **:\n",
    "Để nhân rộng thông qua mạng này, chúng tôi biết rằng đầu ra là,\n",
    "$ A ^ {[L]} = \\ sigma (Z ^ {[L]}) $. Do đó, mã của bạn cần phải tính `dAL` $ = \\ frac {\\ part \\ mathcal {L}} {\\ part A ^ {[L]}} $.\n",
    "Để làm như vậy, hãy sử dụng công thức này (được suy ra bằng phép tính mà bạn không cần kiến thức chuyên sâu):\n",
    "```python\n",
    "dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to AL\n",
    "```\n",
    "\n",
    "Sau đó, bạn có thể sử dụng gradient `dAL` sau kích hoạt này để tiếp tục lùi lại. Như đã thấy trong Hình 5, bây giờ bạn có thể nhập `dAL` vào hàm lùi LINEAR-> SIGMOID mà bạn đã triển khai (sẽ sử dụng các giá trị được lưu trong bộ nhớ cache được lưu trữ bởi hàm L_model_osystem). Sau đó, bạn sẽ phải sử dụng vòng lặp `for` để lặp qua tất cả các lớp khác bằng cách sử dụng hàm lùi LINEAR-> RELU. Bạn nên lưu trữ từng dA, dW và db trong từ điển grads. Để làm như vậy, hãy sử dụng công thức sau:\n",
    "\n",
    "$$grads[\"dW\" + str(l)] = dW^{[l]}\\tag{15}$$\n",
    "\n",
    "Ví dụ: đối với $ l = 3 $, điều này sẽ lưu trữ $ dW ^ {[l]} $ trong `grads [\" dW3 \"]`.\n",
    "\n",
    "** Bài tập **: Triển khai backpropagation cho mô hình *[LINEAR->RELU] $\\times$ (L-1) -> LINEAR -> SIGMOID* model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADED FUNCTION: L_model_backward\n",
    "\n",
    "def L_model_backward(AL, Y, caches):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... \n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "    \n",
    "    # Initializing the backpropagation\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to AL\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"dAL, current_cache\". Outputs: \"grads[\"dAL-1\"], grads[\"dWL\"], grads[\"dbL\"]\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    #grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = None\n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        # lth layer: (RELU -> LINEAR) gradients.\n",
    "        # Inputs: \"grads[\"dA\" + str(l + 1)], current_cache\". Outputs: \"grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n",
    "        ### START CODE HERE ### (approcurrent_cachex. 5 lines)\n",
    "        current_cache = caches[l]\n",
    "        grads[\"dA\" + str(l)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] = linear_activation_backward(grads[\"dA\" + str(l + 1)],current_cache ,activation = \"relu\")\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1 = [[0.41010002 0.07807203 0.13798444 0.10502167]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.05283652 0.01005865 0.01777766 0.0135308 ]]\n",
      "db1 = [[-0.22007063]\n",
      " [ 0.        ]\n",
      " [-0.02835349]]\n",
      "dA1 = [[ 0.12913162 -0.44014127]\n",
      " [-0.14175655  0.48317296]\n",
      " [ 0.01663708 -0.05670698]]\n"
     ]
    }
   ],
   "source": [
    "AL, Y_assess, caches = L_model_backward_test_case()\n",
    "grads = L_model_backward(AL, Y_assess, caches)\n",
    "print_grads(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kết quả mong đợi**\n",
    "\n",
    "<table style=\"width:60%\">\n",
    "  <tr>\n",
    "    <td > dW1 </td> \n",
    "           <td > [[ 0.41010002  0.07807203  0.13798444  0.10502167]\n",
    " [ 0.          0.          0.          0.        ]\n",
    " [ 0.05283652  0.01005865  0.01777766  0.0135308 ]] </td> \n",
    "  </tr> \n",
    "    <tr>\n",
    "    <td > db1 </td> \n",
    "           <td > [[-0.22007063]\n",
    " [ 0.        ]\n",
    " [-0.02835349]] </td> \n",
    "  </tr> \n",
    "  <tr>\n",
    "  <td > dA1 </td> \n",
    "           <td > [[ 0.12913162 -0.44014127]\n",
    " [-0.14175655  0.48317296]\n",
    " [ 0.01663708 -0.05670698]] </td> \n",
    "  </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 - Update Parameters\n",
    "\n",
    "Trong phần này, bạn sẽ cập nhật các thông số của mô hình, sử dụng gradient descent: \n",
    "\n",
    "$$ W^{[l]} = W^{[l]} - \\alpha \\text{ } dW^{[l]} \\tag{16}$$\n",
    "$$ b^{[l]} = b^{[l]} - \\alpha \\text{ } db^{[l]} \\tag{17}$$\n",
    "\n",
    "Khi $\\alpha$ là learning rate. Sau khi tính toán các tham số đã cập nhật, hãy lưu trữ chúng trong từ điển tham số."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài tập**: Thực hiện `update_parameters()` để cập nhật các thông số của bạn bằng cách sử dụng gradient descent.\n",
    "\n",
    "**Hướng dẫn**:\n",
    "Cập nhật các thông số bằng cách sử dụng gradient descent trên mọi $W^{[l]}$ and $b^{[l]}$ for $l = 1, 2, ..., L$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: update_parameters\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] -learning_rate*grads[\"dW\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] -learning_rate*grads[\"db\" + str(l+1)]\n",
    "    ### END CODE HERE ###\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.59562069 -0.09991781 -2.14584584  1.82662008]\n",
      " [-1.76569676 -0.80627147  0.51115557 -1.18258802]\n",
      " [-1.0535704  -0.86128581  0.68284052  2.20374577]]\n",
      "b1 = [[-0.04659241]\n",
      " [-1.28888275]\n",
      " [ 0.53405496]]\n",
      "W2 = [[-0.55569196  0.0354055   1.32964895]]\n",
      "b2 = [[-0.84610769]]\n"
     ]
    }
   ],
   "source": [
    "parameters, grads = update_parameters_test_case()\n",
    "parameters = update_parameters(parameters, grads, 0.1)\n",
    "\n",
    "print (\"W1 = \"+ str(parameters[\"W1\"]))\n",
    "print (\"b1 = \"+ str(parameters[\"b1\"]))\n",
    "print (\"W2 = \"+ str(parameters[\"W2\"]))\n",
    "print (\"b2 = \"+ str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table style=\"width:100%\"> \n",
    "    <tr>\n",
    "    <td > W1 </td> \n",
    "           <td > [[-0.59562069 -0.09991781 -2.14584584  1.82662008]\n",
    " [-1.76569676 -0.80627147  0.51115557 -1.18258802]\n",
    " [-1.0535704  -0.86128581  0.68284052  2.20374577]] </td> \n",
    "  </tr> \n",
    "    <tr>\n",
    "    <td > b1 </td> \n",
    "           <td > [[-0.04659241]\n",
    " [-1.28888275]\n",
    " [ 0.53405496]] </td> \n",
    "  </tr> \n",
    "  <tr>\n",
    "    <td > W2 </td> \n",
    "           <td > [[-0.55569196  0.0354055   1.32964895]]</td> \n",
    "  </tr> \n",
    "    <tr>\n",
    "    <td > b2 </td> \n",
    "           <td > [[-0.84610769]] </td> \n",
    "  </tr> \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Kết luận\n",
    "\n",
    "Chúc mừng bạn đã triển khai tất cả các chức năng cần thiết để xây dựng một mạng nơ-ron sâu!\n",
    "\n",
    "Chúng tôi biết đó là một nhiệm vụ dài nhưng càng về sau, nó sẽ càng ngày càng tốt hơn. Phần tiếp theo của bài tập dễ dàng hơn.\n",
    "\n",
    "Trong nhiệm vụ tiếp theo, bạn sẽ kết hợp tất cả những thứ này lại với nhau để xây dựng hai mô hình:\n",
    "- Mạng nơron hai lớp\n",
    "- Mạng nơron lớp L\n",
    "\n",
    "Trên thực tế, bạn sẽ sử dụng những mô hình này để phân loại hình ảnh mèo và không phải mèo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
